# OfflineLLM

This repository contains configuration and documentation for an offline language model stack based on the Qwen3â€‘32B model.

See [docs/INSTALLATION.md](docs/INSTALLATION.md) for a full installation guide that uses Docker, NVIDIA GPUs and Open WebUI. A sample Compose file using vLLM is provided at `docker-compose.vllm.yaml`.
