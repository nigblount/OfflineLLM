version: "3.9"
services:
  vllm:
    image: vllm/vllm-openai:v0.10.0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
      - VLLM_API_KEY=${VLLM_API_KEY:-changeme}
    command: >
      --model Qwen/Qwen2-32B
      --host 0.0.0.0
      --port 8000
    volumes:
      - ./models:/root/.cache/huggingface
    ports:
      - "8000:8000"
    shm_size: 1g
    restart: unless-stopped
    logging:
      driver: journald

  preview-service:
    build: ./services/preview_service
    ports:
      - "5001:5001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 0
              capabilities: [gpu]
    restart: unless-stopped
    logging:
      driver: journald

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    environment:
      - OPENAI_API_BASE_URL=http://vllm:8000/v1
      - OPENAI_API_KEY=${VLLM_API_KEY:-changeme}
      - OW_CONFIG=/app/backend/data/settings.yaml
    ports:
      - "3000:8080"
    volumes:
      - ./openwebui-data:/app/backend/data
      - ./services/openwebui/settings.yaml:/app/backend/data/settings.yaml:ro
    depends_on:
      - vllm
      - preview-service
    restart: unless-stopped
    logging:
      driver: journald

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./infra/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "9090:9090"
    restart: unless-stopped
    logging:
      driver: journald

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    restart: unless-stopped
    logging:
      driver: journald


volumes:
  models: {}
  openwebui-data: {}
